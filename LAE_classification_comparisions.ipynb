{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is used for two purposes. \n",
    "\n",
    "1. Once 2 (or 3*) members of the team have gone through the LSDCat outputs of a single field, this notebook can be used to make a master list of conflicting sources to be assesed by an independent person. This will make a catalogue similar to LSDCat format, so it can be fed into LAE_scanner. \n",
    "\n",
    "2. Once step 1 is completed and the independent person has given the final classifications, this notebook can be used to make a final list of LSDCat detections. This list will be used with ProFound to extract sources. \n",
    "\n",
    "This will take the LAE_Classifier outputs for the members in one group and will compare results\n",
    "\n",
    "\n",
    "*For v15 We had 3 people to classify per field + a moderator. In v22, this is now 2 people + a moderator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from astropy.io import ascii\n",
    "from astropy.table import Table\n",
    "import glob\n",
    "%matplotlib inline\n",
    "%config Completer.use_jedi = False\n",
    "pd.options.display.max_rows=500"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Select a galaxy\n",
    "\n",
    "All cavaets of a notebook exsists. So it is receomdede to rest the kernal evertime a different galaxy is used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_name = 'MAGPI1505'\n",
    "\n",
    "workdir = '/Users/wnanayakkara/Dropbox/MagPi/LSDCat_outputs_to_groups/v22'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare between group members to produce a list for the final assesor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First compare results between the group members \n",
    "\n",
    "Minor changes have been made to account for change in process between v15 --> v22"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_cat_catalogue = ascii.read(f'{workdir}/{gal_name}_LSDCat.cat',  \n",
    "                              names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' ])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/wnanayakkara/Dropbox/MagPi/LSDCat_classifications/v22/MAGPI1505_MAGPI1505_LSDCat_SSW_class.dat', '/Users/wnanayakkara/Dropbox/MagPi/LSDCat_classifications/v22/MAGPI1505_MAGPI1505_LSDCat_SBA_class.dat']\n"
     ]
    }
   ],
   "source": [
    "class_files = glob.glob(f'{workdir}/{gal_name}*class.dat')\n",
    "print(class_files)\n",
    "assert len(class_files)==2, 'there are more or less than 2 files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_p1 = ascii.read(class_files[0], \n",
    "          names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' , 'Galaxy'] ).to_pandas().set_index('I')\n",
    "\n",
    "\n",
    "class_p2 = ascii.read(class_files[1], \n",
    "          names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' , 'Galaxy'] ).to_pandas().set_index('I')\n",
    "\n",
    "# class_p3 = ascii.read(class_files[2], \n",
    "#           names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' , 'Galaxy'] ).to_pandas().set_index('I')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_classifications = pd.merge(class_p1, class_p2, left_index=True, right_index=True, \n",
    "                               how='outer', suffixes=('_p1', '_p2'))\n",
    "\n",
    "\n",
    "# all_classifications = pd.merge(all_classifications, class_p3.add_suffix('_p3'), left_index=True, right_index=True, \n",
    "#                                 how='outer')\n",
    "\n",
    "all_classification_grades =  all_classifications[['Galaxy_p1', 'Galaxy_p2']]#, 'Galaxy_p3']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "284"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are \", len(all_classification_grades), \"candidates in total \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  177  common classifications\n"
     ]
    }
   ],
   "source": [
    "## all common between the group\n",
    "all_common = all_classification_grades.query('Galaxy_p1==Galaxy_p2')\n",
    "print('There are ', len(all_common), ' common classifications')\n",
    "\n",
    "\n",
    "# ## When there are 3 aggregators it is a bit complex\n",
    "# all_common = all_classification_grades.query('Galaxy_p1==Galaxy_p2==Galaxy_p3')\n",
    "# print('There are ', len(all_common), ' common classifications')\n",
    "\n",
    "# diff_p3= all_classification_grades.query('(Galaxy_p1==Galaxy_p2) and  (Galaxy_p1!=Galaxy_p3)')\n",
    "# print('p1==p2!=p3', len(diff_p3))\n",
    "\n",
    "# diff_p1= all_classification_grades.query('(Galaxy_p3==Galaxy_p2) and  (Galaxy_p1!=Galaxy_p3)')\n",
    "# print('p3==p2!=p1', len(diff_p1))\n",
    "\n",
    "# diff_p2= all_classification_grades.query('(Galaxy_p3==Galaxy_p1) and  (Galaxy_p2!=Galaxy_p3)')\n",
    "# print('p3==p1!=p2', len(diff_p2))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare a new file to input to LAE_scanner for sources with disagreements\n",
    "\n",
    "If two classifiers have a common grade, we keep it.\n",
    "\n",
    "However, if the common grade is 3, then these need to be sent to the final assesor. \n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "177  sources are agreeable out of  284\n",
      "There are  1 source/s which need revisiting from the agreed list because they are classified as maybe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/r3/8rkwf3z12mgd39qrrfckpr3s0d32bj/T/ipykernel_4951/1573448613.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  agreed['agreed_grade'] = agreed.mode(axis=1)\n"
     ]
    }
   ],
   "source": [
    "agreed = all_classification_grades.query('(Galaxy_p1==Galaxy_p2)')\n",
    "\n",
    "### if 3 people\n",
    "# agreed = all_classification_grades.query('(Galaxy_p3==Galaxy_p2)  | (Galaxy_p3==Galaxy_p1) | (Galaxy_p1==Galaxy_p2)')\n",
    "\n",
    "print(len(agreed), ' sources are agreeable out of ', len(all_classification_grades))\n",
    "\n",
    "agreed['agreed_grade'] = agreed.mode(axis=1)\n",
    "\n",
    "\n",
    "print('There are ', len(agreed.query('agreed_grade==3')), 'source/s which need revisiting from the agreed list because they are classified as maybe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All other sources have two(three) different grades. They also need to be revisted by the group members and a common grade should be agreed upon. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107 sources with two different classifications\n"
     ]
    }
   ],
   "source": [
    "to_be_agreed = all_classification_grades[~all_classification_grades.index.isin(agreed.index)]\n",
    "\n",
    "print(len(to_be_agreed), 'sources with two different classifications')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lets add all that needs to be discussed together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_be_discussed = all_classifications.reindex(to_be_agreed.index)\n",
    "## add the maybe ones\n",
    "to_be_discussed = pd.concat([to_be_discussed, all_classifications.reindex(agreed.query('agreed_grade==3').index)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get the index based on LSD cat catalogue file. \n",
    "The retention of comments in the .cat file is important! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_inds = [np.where(index==LSD_cat_catalogue['I'])[0][0] for index in to_be_discussed.index  ]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use the file written below to consolidate the results in the group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_cat_catalogue[LSD_inds].write(f'{workdir}/{gal_name}_combine_catalogue_to_be_consolidated.dat', \n",
    "                       format='ascii.fixed_width_no_header', delimiter=None, )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So basically, the above file should be run again with LAE_scanner and all sources to be agreed upon. \n",
    "\n",
    "Then technically, the newly classified sources should be combined with the previous list (and remove the duplicates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a final list of detected sources to be fed to Profound\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reconcile with the group + assesor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### add a real file for this in future\n",
    "class_reconciliation = ascii.read(f'{workdir}/{gal_name}_reassessment_ESW.dat', \n",
    "          names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' , 'Galaxy'] ).to_pandas().set_index('I')\n",
    "\n",
    "\n",
    "### now we can now have maybe objects\n",
    "assert len(class_reconciliation.query('Galaxy==3'))==0 , \"There cannot be any MAYBE objects, all should be YES or NO\"\n",
    "class_reconciliation = class_reconciliation.rename(columns= {'Galaxy': 'agreed_grade'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "### make sure the total number of sources are preserved\n",
    "sources_in_reconciliation_list =  len(class_reconciliation)\n",
    "\n",
    "##agreed is everything except maybe\n",
    "sources_agreed_on = len(all_classifications.reindex(agreed.query('agreed_grade!=3').index))\n",
    "\n",
    "assert len(all_classifications) == sources_in_reconciliation_list + sources_agreed_on, \"Source numbers don't match\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = class_p1.reindex(agreed.query('agreed_grade==1').index)\n",
    "\n",
    "final_output.drop('Galaxy', axis=1, inplace=True)\n",
    "final_output['agreed_grade'] = agreed.query('agreed_grade==1').agreed_grade\n",
    "\n",
    "\n",
    "final_output = pd.concat([final_output, class_reconciliation.query('agreed_grade==1')], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check if any of the 'real' sources are duplicated\n",
    "\n",
    "This means if there are multiple lines for a galaxy, LSDCat can identify those lines independently of each other. \n",
    "In this case, a judgement call should be made on which source to keep/remove. \n",
    "Ideally, the source with highest NPIX or highest S/N should be kept. \n",
    "It is always better to go to the cube and look in these situtations. \n",
    "Specially because Ly-alpha is extended so basing a judement on purely pixels vs S/N might not be best. \n",
    "I guess it doesn't really matter at the end because people who study halo properties would go to the NBs anyways. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "targets with multiple detections\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "I\n",
       "120    84\n",
       "67     45\n",
       "Name: ID, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print('targets with multiple detections')\n",
    "final_output[final_output.duplicated('ID')].ID\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X_PEAK_SN</th>\n",
       "      <th>Y_PEAK_SN</th>\n",
       "      <th>Z_PEAK_SN</th>\n",
       "      <th>NPIX</th>\n",
       "      <th>DETSN_MAX</th>\n",
       "      <th>agreed_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>45</td>\n",
       "      <td>159.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>872.0</td>\n",
       "      <td>47</td>\n",
       "      <td>13.987032</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>45</td>\n",
       "      <td>159.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>2460.0</td>\n",
       "      <td>108</td>\n",
       "      <td>20.356070</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>84</td>\n",
       "      <td>132.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1592.0</td>\n",
       "      <td>594</td>\n",
       "      <td>25.861885</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>84</td>\n",
       "      <td>132.0</td>\n",
       "      <td>329.0</td>\n",
       "      <td>1926.0</td>\n",
       "      <td>77</td>\n",
       "      <td>17.280361</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ID  X_PEAK_SN  Y_PEAK_SN  Z_PEAK_SN  NPIX  DETSN_MAX  agreed_grade\n",
       "I                                                                      \n",
       "64   45      159.0      165.0      872.0    47  13.987032             1\n",
       "67   45      159.0      165.0     2460.0   108  20.356070             1\n",
       "119  84      132.0      329.0     1592.0   594  25.861885             1\n",
       "120  84      132.0      329.0     1926.0    77  17.280361             1"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### manually put the IDS here 'ID==A| ID==B| ID==C' henceforth\n",
    "final_output.query('ID==84| ID==45').sort_values('ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X_PEAK_SN</th>\n",
       "      <th>Y_PEAK_SN</th>\n",
       "      <th>Z_PEAK_SN</th>\n",
       "      <th>NPIX</th>\n",
       "      <th>DETSN_MAX</th>\n",
       "      <th>agreed_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>164</td>\n",
       "      <td>203</td>\n",
       "      <td>234</td>\n",
       "      <td>3543</td>\n",
       "      <td>307</td>\n",
       "      <td>45.761883</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>244</th>\n",
       "      <td>164</td>\n",
       "      <td>203</td>\n",
       "      <td>234</td>\n",
       "      <td>3330</td>\n",
       "      <td>20</td>\n",
       "      <td>13.356362</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ID  X_PEAK_SN  Y_PEAK_SN  Z_PEAK_SN  NPIX  DETSN_MAX  agreed_grade\n",
       "I                                                                       \n",
       "246  164        203        234       3543   307  45.761883             1\n",
       "244  164        203        234       3330    20  13.356362             1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# final_output.query('ID==164')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if the above is none, then we are good to go and provide the file for profound\n",
    "\n",
    "**UPADTE 8/06/2021** This file (written below) not used for profound anymore. \n",
    "The file in the next section which has all columns from LSDCat_Measure will be used. \n",
    "This is because NB with the limits given by those extra columns in Profound. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "### NOT USED \n",
    "# final_output.to_csv(f'../LSDCat_classifications/{gal_name}_ELGs_final_output.dat', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perfrom any duplication checks with LAE_GUI \n",
    "\n",
    "If needed use the file generated below to interact with the duplicated sources. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 64,  67, 119, 120])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output.query('ID==84| ID==45').sort_values('ID').index.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "LSD_inds = final_output.query('ID==25| ID==118| ID==72').sort_values('ID').index.values\n",
    "LSD_cat_catalogue[LSD_inds-1].write(f'{workdir}/{gal_name}_LSDCat_duplicate_checks.dat', \n",
    "                       format='ascii.fixed_width_no_header', delimiter=None, )\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Collate final detected sources with LSDCat Flux files to be fed into Profound\n",
    "(from LSDCat Measurement Routine Version 1.51) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.utils.diff import report_diff_values\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      I   ID X_PEAK_SN Y_PEAK_SN Z_PEAK_SN NPIX DETSN_MAX\n",
      "     --- --- --------- --------- --------- ---- ---------\n",
      "       1   1       312       138         0    8 11.882159\n",
      "       2   2       275       154         0   73 21.465412\n",
      "       3   3        69        43        14   13 12.381769\n",
      "       4   3        68        43      2179   20 12.904837\n",
      "       5   4        91        36        15    2 10.333988\n",
      "       6   5       170       270        20  172 40.232159\n",
      "       7   5       170       273       316    1  10.18404\n",
      "       8   6       283       340        20  102 32.923962\n",
      "       9   6       283       342       310  152  55.08073\n",
      "      10   6       282       343       696  199 54.162987\n",
      "     ... ...       ...       ...       ...  ...       ...\n",
      "     310 208       231       131      3205    8 12.030111\n",
      "     311 209       189        40      3228    3 10.412211\n",
      "     312 210        94       367      3243    4 10.400422\n",
      "     313 211       348        43      3251  190   24.5856\n",
      "     314 212       311        28      3282    8 11.304935\n",
      "     315 213        42       187      3334    6 11.061861\n",
      "     316 214       345       175      3423   53 18.833124\n",
      "     317 215       336       107      3536  471 73.641457\n",
      "     318 216       366       323      3549   21 11.735522\n",
      "     319 217       136       310      3595   19 11.631486\n",
      "     320 218        57       312      3679    6 10.583179\n",
      "     Length = 320 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### first sanity check to see if the files are the same\n",
    "### this is because for the first five galaxies the larger files were created after the group assignments were made\n",
    "### this is not necessary in future\n",
    "gal_name = 'MAGPI1501'\n",
    "\n",
    "LSD_cat_catalogue = ascii.read(f'{workdir}/{gal_name}_LSDCat.cat',  \n",
    "                              names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' ])\n",
    "\n",
    "LSD_cat_catalogue_new = ascii.read(f'{workdir}/{gal_name}_LSDCat.cat',  \n",
    "                              names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' ])\n",
    "\n",
    "\n",
    "identical = report_diff_values(LSD_cat_catalogue, LSD_cat_catalogue_new, fileobj=sys.stdout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not identical:\n",
    "    print(\"ERROR: outputs are not identical\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: UnitsWarning: '10**(-20)*erg/s/cm**2' contains multiple slashes, which is discouraged by the FITS standard [astropy.units.format.generic]\n"
     ]
    }
   ],
   "source": [
    "LSD_cat_fluxes = Table.read(f'{workdir}/{gal_name}_LSDCat_fluxes.fits').to_pandas().set_index('I')\n",
    "\n",
    "\n",
    "\n",
    "gal_detections = pd.read_csv(f'{workdir}/{gal_name}_ELGs_final_output.dat', sep='\\t', index_col='I')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_combined = pd.merge(gal_detections, LSD_cat_fluxes, left_index=True, right_index=True, how='inner', \n",
    "         suffixes=('_lsdcat', '_lsdmeasure'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_compare = ['ID', 'X_PEAK_SN','Y_PEAK_SN','Z_PEAK_SN','NPIX']\n",
    "\n",
    "\n",
    "for cols in cols_to_compare:\n",
    "    \n",
    "    if not gal_combined[cols+'_lsdcat'].equals(gal_combined[cols+'_lsdmeasure']):\n",
    "        print('values in', cols,  'columns dont match')\n",
    "    \n",
    "    \n",
    "# 'DETSN_MAX' need to be compared seperately because it is a float\n",
    "\n",
    "cols ='DETSN_MAX'\n",
    "if len(gal_combined[~(np.round(gal_combined[cols+'_lsdcat'], 2) == np.round(gal_combined[cols+'_lsdmeasure'], 2))])!=0:\n",
    "    print('there are unmatched values')\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "gal_combined.to_csv(f'{workdir}/{gal_name}_LSDCatFlux_detections_only.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LSDcat final results of all objects and noise \n",
    "\n",
    "This will create a final list of classifications for all LSDcat detections (real/maybe/noise). \n",
    "\n",
    "This is for record keeping purposes i.e. for a paper, proposals on LAE detection rates etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_cat_fluxes = Table.read(f'{workdir}/{gal_name}_LSDCat_fluxes.fits').to_pandas().set_index('I')\n",
    "\n",
    "class_reconciliation = ascii.read(f'/Users/wnanayakkara/Dropbox/MagPi/LSDCat_classifications/{gal_name}_reassessment_TNA.dat', \n",
    "          names=['I' , 'ID' , 'X_PEAK_SN' , 'Y_PEAK_SN' , 'Z_PEAK_SN' , 'NPIX' , 'DETSN_MAX' , 'Galaxy'] ).to_pandas().set_index('I')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_cat_fluxes.loc[agreed.query('agreed_grade!=3').index, 'agreed_grade'] = agreed.query('agreed_grade!=3').agreed_grade\n",
    "\n",
    "LSD_cat_fluxes.loc[class_reconciliation.index, 'agreed_grade'] = class_reconciliation.Galaxy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>X_PEAK_SN</th>\n",
       "      <th>Y_PEAK_SN</th>\n",
       "      <th>Z_PEAK_SN</th>\n",
       "      <th>NPIX</th>\n",
       "      <th>DETSN_MAX</th>\n",
       "      <th>X_SN</th>\n",
       "      <th>Y_SN</th>\n",
       "      <th>Z_SN</th>\n",
       "      <th>RA_SN</th>\n",
       "      <th>...</th>\n",
       "      <th>SIGMA_ISO</th>\n",
       "      <th>F_KRON</th>\n",
       "      <th>F_KRON_ERR</th>\n",
       "      <th>F_2KRON</th>\n",
       "      <th>F_2KRON_ERR</th>\n",
       "      <th>F_3KRON</th>\n",
       "      <th>F_3KRON_ERR</th>\n",
       "      <th>F_4KRON</th>\n",
       "      <th>F_4KRON_ERR</th>\n",
       "      <th>agreed_grade</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>I</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [ID, X_PEAK_SN, Y_PEAK_SN, Z_PEAK_SN, NPIX, DETSN_MAX, X_SN, Y_SN, Z_SN, RA_SN, DEC_SN, LAMBDA_SN, X_FLUX, Y_FLUX, Z_FLUX, RA_FLUX, DEC_FLUX, LAMBDA_FLUX, X_SFLUX, Y_SFLUX, Z_SFLUX, RA_SFLUX, DEC_SFLUX, LAMBDA_SFLUX, X_1MOM, Y_1MOM, RA_1MOM, DEC_1MOM, Z_NB_MIN, Z_NB_MAX, Z_DIFF_FLAG, LAMBDA_NB_MIN, LAMBDA_NB_MAX, X_2MOM, Y_2MOM, XY_2MOM, RKRON, RKRON_FLAG, SIGMA_ISO, F_KRON, F_KRON_ERR, F_2KRON, F_2KRON_ERR, F_3KRON, F_3KRON_ERR, F_4KRON, F_4KRON_ERR, agreed_grade]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 48 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LSD_cat_fluxes.query('agreed_grade!=agreed_grade')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "LSD_cat_fluxes.to_csv(f'{workdir}/{gal_name}_LSDCat_fluxes_and_final_grades.csv')\n",
    "                      \n",
    "                      \n",
    "                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:astro]",
   "language": "python",
   "name": "conda-env-astro-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
